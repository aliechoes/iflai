{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /pstore/home/shetabs1/code/iflai\n",
      "Requirement already satisfied: numpy in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from iflai==0.0.1) (1.21.1)\n",
      "Requirement already satisfied: pandas in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from iflai==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from iflai==0.0.1) (0.24.2)\n",
      "Requirement already satisfied: scikit-image in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from iflai==0.0.1) (0.18.2)\n",
      "Requirement already satisfied: xgboost in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from iflai==0.0.1) (1.4.2)\n",
      "Requirement already satisfied: torch in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from iflai==0.0.1) (1.9.0)\n",
      "Requirement already satisfied: torchvision in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from iflai==0.0.1) (0.10.0)\n",
      "Requirement already satisfied: skorch in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from iflai==0.0.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from pandas->iflai==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from pandas->iflai==0.0.1) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->iflai==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from scikit-image->iflai==0.0.1) (2021.8.8)\n",
      "Requirement already satisfied: networkx>=2.0 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from scikit-image->iflai==0.0.1) (2.6.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from scikit-image->iflai==0.0.1) (1.7.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from scikit-image->iflai==0.0.1) (8.3.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from scikit-image->iflai==0.0.1) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from scikit-image->iflai==0.0.1) (2.9.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from scikit-image->iflai==0.0.1) (3.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->iflai==0.0.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->iflai==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->iflai==0.0.1) (2.4.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from scikit-learn->iflai==0.0.1) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from scikit-learn->iflai==0.0.1) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in /pstore/apps/Python/3.8.3-2020.07/lib/python3.8/site-packages (from skorch->iflai==0.0.1) (4.47.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from skorch->iflai==0.0.1) (0.8.9)\n",
      "Requirement already satisfied: typing-extensions in /pstore/home/shetabs1/.local/lib/python3.8/site-packages (from torch->iflai==0.0.1) (3.10.0.0)\n",
      "Building wheels for collected packages: iflai\n",
      "  Building wheel for iflai (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iflai: filename=iflai-0.0.1-py3-none-any.whl size=23042 sha256=41fa52a5ab05293f6e1e2d8b6eacb96265b480cd3afcb43e95ce521d65da58ef\n",
      "  Stored in directory: /local/2772878/pip-ephem-wheel-cache-y62kgf3y/wheels/77/c9/46/be8aac478e8f67c427d0996a39b13c1213341ddb146b974964\n",
      "Successfully built iflai\n",
      "Installing collected packages: iflai\n",
      "  Attempting uninstall: iflai\n",
      "    Found existing installation: iflai 0.0.1\n",
      "    Uninstalling iflai-0.0.1:\n",
      "      Successfully uninstalled iflai-0.0.1\n",
      "Successfully installed iflai-0.0.1\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/pstore/apps/Python/3.8.3-2020.07/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install /pstore/home/shetabs1/code/iflai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from iflai.dl.util import read_data, get_statistics_h5, calculate_weights\n",
    "from iflai.dl.dataset import train_validation_test_split_wth_augmentation, Dataset_Generator_Preprocessed_h5\n",
    "from iflai.dl.models import PretrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import LRScheduler, Checkpoint\n",
    "import torch.optim as optim\n",
    "from skorch.helper import predefined_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2aab5f0a2f70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_value = 42\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"synapse_formation\"\n",
    "only_channels = [0,3,4,5,6]\n",
    "metadata = pd.read_csv(\"/pstore/home/shetabs1/data/iflai/metadata_subset.csv\")\n",
    "scaling_factor = 4095.\n",
    "reshape_size = 128\n",
    "num_channels = len(only_channels)\n",
    "train_transform = transforms.Compose(\n",
    "        [transforms.RandomVerticalFlip(),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.RandomRotation(45)])\n",
    "test_transform = transforms.Compose([])\n",
    "batch_size = 256\n",
    "num_workers = 2\n",
    "dev=\"cuda\"\n",
    "\n",
    "label_map = {'B_cell':0,   \n",
    "             'T_cell':1,\n",
    "             'T_cell_with_signaling':2,\n",
    "             'T_cell_with_B_cell_fragments':3, \n",
    "             'B_T_cell_in_one_layer':4,\n",
    "             'Synapses_without_signaling':5,\n",
    "            'Synapses_with_signaling':6,\n",
    "             'No_cell_cell_interaction':7,\n",
    "             'Multiplets':8, \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = metadata.label.isin(['B_cell',   'B_T_cell_in_one_layer',\n",
    "        'Multiplets', 'Synapses_with_signaling',\n",
    "       'T_cell_with_B_cell_fragments', 'T_cell',\n",
    "       'No_cell_cell_interaction', 'Synapses_without_signaling',\n",
    "         'T_cell_with_signaling'])\n",
    "\n",
    "metadata = metadata.loc[indx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata, validation_metadata, test_metadata = train_validation_test_split_wth_augmentation(metadata, metadata[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = train_metadata.reset_index(drop = True)\n",
    "validation_metadata = validation_metadata.reset_index(drop = True)\n",
    "test_metadata = test_metadata.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path_to_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-581bb9177989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dataset = Dataset_Generator_Preprocessed_h5(path_to_data=path_to_data,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                       \u001b[0mset_indx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_indx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                       \u001b[0mscaling_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaling_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                       \u001b[0mreshape_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreshape_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                       \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_to_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset_Generator_Preprocessed_h5(path_to_data=path_to_data,\n",
    "                                                      set_indx=train_indx,\n",
    "                                                      scaling_factor=scaling_factor,\n",
    "                                                      reshape_size=reshape_size,\n",
    "                                                      transform=train_transform,\n",
    "                                                      data_map=data_map,\n",
    "                                                      only_channels=only_channels,\n",
    "                                                      num_channels=num_channels)\n",
    "\n",
    "trainloader = DataLoader(train_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset_Generator_Preprocessed_h5 in module iflai.dl.dataset:\n",
      "\n",
      "class Dataset_Generator_Preprocessed_h5(torch.utils.data.dataset.Dataset)\n",
      " |  Dataset_Generator_Preprocessed_h5(*args, **kwds)\n",
      " |  \n",
      " |  An abstract class representing a :class:`Dataset`.\n",
      " |  \n",
      " |  All datasets that represent a map from keys to data samples should subclass\n",
      " |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      " |  data sample for a given key. Subclasses could also optionally overwrite\n",
      " |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      " |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      " |  of :class:`~torch.utils.data.DataLoader`.\n",
      " |  \n",
      " |  .. note::\n",
      " |    :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      " |    sampler that yields integral indices.  To make it work with a map-style\n",
      " |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset_Generator_Preprocessed_h5\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, idx)\n",
      " |  \n",
      " |  __init__(self, path_to_data, set_indx, scaling_factor=4095.0, reshape_size=64, data_map=[], transform=None, means=None, stds=None, only_channels=[], channels_to_shuffle=[], only_classes=None, num_channels=12, return_only_image=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __parameters__ = ()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skorch",
   "language": "python",
   "name": "skorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
